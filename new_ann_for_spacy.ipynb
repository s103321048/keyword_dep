{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rewrite a ann_text which return dep_list I can direct put into graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import neuralcoref\n",
    "from spacy import displacy # https://spacy.io/usage/visualizers\n",
    "def show_depparse(text):\n",
    "    doc = nlp(text)\n",
    "    displacy.render(doc, style='dep',jupyter=True)\n",
    "\n",
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove_pronoun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dep_create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the DET\n",
      "body NOUN\n",
      "of ADP\n",
      "a DET\n",
      "fighter NOUN\n",
      "pilot NOUN\n",
      "who PRON\n",
      "have VERB\n",
      "go VERB\n",
      "miss VERB\n",
      "follow VERB\n",
      "a DET\n",
      "mid ADJ\n",
      "- NOUN\n",
      "air NOUN\n",
      "collision NOUN\n",
      "last ADJ\n",
      "month NOUN\n",
      "be VERB\n",
      "yesterday NOUN\n",
      "find VERB\n",
      "near ADP\n",
      "a DET\n",
      "fishing NOUN\n",
      "port NOUN\n",
      "in ADP\n",
      "Pingtung PROPN\n",
      "County PROPN\n",
      ", PUNCT\n",
      "the DET\n",
      "air NOUN\n",
      "force NOUN\n",
      "say VERB\n",
      ". PUNCT\n",
      "===== next semt =====\n"
     ]
    }
   ],
   "source": [
    "def ann_text(text):\n",
    "    doc = nlp(text)\n",
    "    for sent_idx, sent in enumerate(doc.sents):\n",
    "        for tok_idx, tok in enumerate(sent):\n",
    "            print(tok.lemma_, tok.pos_)\n",
    "        print(\"===== next semt =====\")\n",
    "\n",
    "t = \"The body of a fighter pilot who had gone missing following a mid-air collision last month was yesterday found near a fishing port in Pingtung County, the air force said.\"\n",
    "ann_text(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pan Ying-chun Pan Ying-chun: [Pan Ying-chun, him]\n",
      "Pan’s None\n",
      "yesterday None\n",
      "=====\n",
      "True\n",
      "[the body: [the body, the body], Pan Ying-chun: [Pan Ying-chun, him], Pan’s brother: [Pan’s brother, he, he, his, his brother, him]]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# Add neural coref to SpaCy's pipe\n",
    "import neuralcoref\n",
    "neuralcoref.add_to_pipe(nlp)\n",
    "\n",
    "#t = \"Pan’s body was identified through its air force uniform, name tag and other items, the office said, adding that DNA testing would confirm the identity.\"\n",
    "#t = \"Angela lives in Boston. She is quite happy in that city.\"\n",
    "doc2 = nlp(t)\n",
    "for ent in doc2.ents:\n",
    "    print(ent, ent._.coref_cluster)\n",
    "\n",
    "print('=====')\n",
    "doc = nlp(t)\n",
    "print(doc._.has_coref)\n",
    "print(doc._.coref_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neuralcoref.neuralcoref.Cluster"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc._.coref_clusters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"“Since many of the things found on the body belonged to Pan Ying-chun, it is probably him,” Pan’s brother told reporters at the morgue yesterday. Finding the body was enough, he said, adding that he just wants to give his brother a proper funeral and send him off.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lo Shang-hua (羅尚樺)': ['his', 'he', 'Lo'], 'his aircraft': ['his aircraft'], 'Pan’s': ['his', 'He', 'his'], 'The Taitung District Prosecutors’ Office': ['it', 'its']}\n",
      "[('his', 'Lo Shang-hua (羅尚樺)'), ('he', 'Lo Shang-hua (羅尚樺)'), ('Lo', 'Lo Shang-hua (羅尚樺)'), ('his aircraft', 'his aircraft'), ('his', 'Pan’s'), ('He', 'Pan’s'), ('his', 'Pan’s'), ('it', 'The Taitung District Prosecutors’ Office'), ('its', 'The Taitung District Prosecutors’ Office')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('neuralcoref', <neuralcoref.neuralcoref.NeuralCoref at 0x7fafd846c310>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuralcoref.add_to_pipe(nlp)\n",
    "# t = 'Angela lives in Boston. She is quite happy in that city. She enjoy her life.'\n",
    "doc = nlp(t)\n",
    "\n",
    "cvt_dict = dict()\n",
    "\n",
    "for s in doc._.coref_clusters:\n",
    "    cvt_dict[str(s.main)] = [str(i) for i in s.mentions if i != s.main]\n",
    "print(cvt_dict)\n",
    "\n",
    "pn_list = []\n",
    "for pn_main in cvt_dict:\n",
    "    for pn in cvt_dict[pn_main]:\n",
    "        pn_list.append( (pn, pn_main) )\n",
    "print(pn_list)\n",
    "\n",
    "no_pronoun_t = []\n",
    "for tok in doc:\n",
    "    if tok.lemma_ == \"-PRON-\":\n",
    "        for pn_idx, pn in enumerate(pn_list):\n",
    "            if tok.text == pn[0]:\n",
    "                no_pronoun_t.append(pn[1])\n",
    "                del(pn_list[pn_idx])\n",
    "    else:\n",
    "        no_pronoun_t.append(tok.text)\n",
    "new_t = \" \".join(no_pronoun_t)\n",
    "new_t\n",
    "nlp.remove_pipe(\"neuralcoref\")\n",
    "# for main_pn in cvt_dict:\n",
    "#     for pn in cvt_dict[main_pn]:\n",
    "#         t = t.replace(pn, main_pn)\n",
    "\n",
    "\n",
    "# for tok in doc:\n",
    "#     if tok.lemma_ == \"-PRON-\":\n",
    "#         print(tok.text)\n",
    "#     else:\n",
    "#         print(tok.lemma_)\n",
    "\n",
    "# print(doc._.coref_clusters)\n",
    "# print(doc._.coref_clusters[1].mentions)\n",
    "# print(doc._.coref_clusters[1].mentions[-1])\n",
    "# print(doc._.coref_clusters[1].mentions[-1]._.coref_cluster.main)\n",
    "\n",
    "# token = doc[-1]\n",
    "# print(\"!\", token)\n",
    "# print(token._.in_coref)\n",
    "# print(token._.coref_clusters[0])\n",
    "\n",
    "# span = doc[-1:]\n",
    "# print(\"!\", span)\n",
    "# print(span._.is_coref)\n",
    "# print(span._.coref_cluster.main)\n",
    "# print(span._.coref_cluster.main._.coref_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The other pilot, Lo Shang-hua (羅尚樺), ejected from his aircraft after the collision, but he did not have any vital signs when found at sea and was pronounced dead after being taken to hospital later that day. Lo was posthumously promoted from the rank of first lieutenant to major. Pan’s body has been transported to his home in Taitung County, the air force said. He is thought to have also ejected from his aircraft. The Taitung District Prosecutors’ Office said that it is continuing its investigation into the cause of the accident.\n",
      "The other pilot , Lo Shang - hua ( 羅尚樺 ) , ejected from Lo Shang-hua (羅尚樺) Pan’s Pan’s aircraft after the collision , but Lo Shang-hua (羅尚樺) did not have any vital signs when found at sea and was pronounced dead after being taken to hospital later that day . Lo was posthumously promoted from the rank of first lieutenant to major . Pan ’s body has been transported to home in Taitung County , the air force said . Pan’s is thought to have also ejected from aircraft . The Taitung District Prosecutors ’ Office said that The Taitung District Prosecutors’ Office is continuing The Taitung District Prosecutors’ Office investigation into the cause of the accident .\n"
     ]
    }
   ],
   "source": [
    "print(t)\n",
    "print(new_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Angela lives in Boston . Angela is quite happy in that city . Angela enjoy Angela life .'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_pronoun(input_t): # replace pronoun with original noun\n",
    "    neuralcoref.add_to_pipe(nlp)\n",
    "    doc = nlp(input_t)\n",
    "    cvt_dict = dict()\n",
    "    for s in doc._.coref_clusters: # find pronouns save it as dict\n",
    "        cvt_dict[str(s.main)] = [str(i) for i in s.mentions if i != s.main]\n",
    "#    print(\"pronoun dict:\", cvt_dict)\n",
    "\n",
    "    pn_list = [] # save list as (pronoun, origin noun)\n",
    "    for pn_main in cvt_dict:\n",
    "        for pn in cvt_dict[pn_main]:\n",
    "            pn_list.append( (pn, pn_main) )\n",
    "    rm_dup_pronouns(pn_list)\n",
    "#    print(\"pronoun list without dup:\", pn_list)\n",
    "    \n",
    "    no_pronoun_t = [] # replace pronoun with origin noun\n",
    "    for tok in doc:\n",
    "        if tok.lemma_ == \"-PRON-\":\n",
    "            for pn_idx, pn in enumerate(pn_list):\n",
    "                if tok.text == pn[0]:\n",
    "                    no_pronoun_t.append(pn[1])\n",
    "                    del(pn_list[pn_idx])\n",
    "        else:\n",
    "            no_pronoun_t.append(tok.text)\n",
    "    new_t = \" \".join(no_pronoun_t)\n",
    "    nlp.remove_pipe(\"neuralcoref\")\n",
    "    return new_t\n",
    "\n",
    "def rm_dup_pronouns(pn_list):\n",
    "    rm_idx_list = []\n",
    "    for idx, i in enumerate(pn_list):\n",
    "        if i[0] == i[1]:\n",
    "            rm_idx_list.append(idx)\n",
    "    rm_idx_list.reverse()\n",
    "    for rm_idx in rm_idx_list:\n",
    "        del pn_list[rm_idx]\n",
    "    # # example\n",
    "    # pn_list = [('his', 'Lo Shang-hua (羅尚樺)'),(\"it\",\"it\"), (\"the\",\"the\"), ('he', 'Lo Shang-hua (羅尚樺)'), ('Lo', 'Lo Shang-hua (羅尚樺)'), ('his aircraft', 'his aircraft'), ('his', 'Pan’s'), ('He', 'Pan’s'), ('his', 'Pan’s'), ('it', 'The Taitung District Prosecutors’ Office'), ('its', 'The Taitung District Prosecutors’ Office')]\n",
    "    # rm_dup_pronouns(pn_list)\n",
    "    # pn_list\n",
    "    \n",
    "t = 'Angela lives in Boston. She is quite happy in that city. She enjoy her life.'\n",
    "remove_pronoun(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
